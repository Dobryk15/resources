{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Gradient Boosting for Prediction and Inference\n",
    "\n",
    "### Lesson 1\n",
    "In this notebook we will walk through Decision Trees and Random Forests.  These methods serve as the foundations to Gradient Boosted Trees, and understanding them deeply is key to developing intuition around the use of Gradient Boosting."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Decision Trees\n",
    "\n",
    "- \"Similarity Principle\" - two values of x that are \"similar\" should have similar predictions about y.\n",
    "- For numeric predictors, similarity means that $|x_1 - x_2|$ is small\n",
    "- For categorical predictors, less clear how to define similarity (more about this later)\n",
    "\n",
    "\n",
    "### Example: Linear Regression\n",
    "- Consider linear regression on a single variable.\n",
    "- Model: $y = \\alpha + \\beta x$\n",
    "- Similarity comes from the fact that the function is continuous\n",
    "- Lines give an easily specified set of reasonable functions, that are governed by few (two) parameters\n",
    "\n",
    "- Q: What is another class of functions that can be specified with few parameters?\n",
    "- A: There are many, but in particular: step functions!\n",
    "    - $f(x) = a \\mbox{ if } x\\leq c$\n",
    "    - $f(x) = b \\mbox{ if } x> c$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Fitting a step function\n",
    "- In linear regression, there is matrix algebra that lets you find the best $\\alpha, \\beta$ to minimze the mean squared error on a data set.\n",
    "- For a step function, you just try every possible \"split\" $c$ and then choose $a$ and $b$ to be the means of the points on each side of the split respectively"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.seed(0)\n",
    "npts=25\n",
    "xvec = np.round(np.random.uniform(0,10, size=25), decimals = 2)\n",
    "yvec = 2*(xvec<=7) + 6*(xvec>7) + np.round(np.random.normal(0,1,size=25), decimals=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.PathCollection at 0x12bcbd278>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.scatter(xvec, yvec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.2 3.79 3.898 4.675\n",
      "0.71 2.355 4.028 4.469\n",
      "0.87 2.703 4.056 4.482\n",
      "1.18 2.778 4.107 4.438\n",
      "3.83 2.632 4.21 4.277\n",
      "4.24 2.267 4.408 3.839\n",
      "4.38 2.194 4.555 3.552\n",
      "4.61 2.121 4.728 3.196\n",
      "5.29 2.279 4.802 3.208\n",
      "5.45 2.319 4.944 3.022\n",
      "5.49 2.203 5.223 2.428\n",
      "5.68 2.233 5.427 2.13\n",
      "6.03 2.218 5.71 1.631\n",
      "6.46 2.161 6.099 0.855\n",
      "7.15 2.443 6.071 1.516\n",
      "7.78 2.676 6.059 2.039\n",
      "7.81 2.826 6.164 2.251\n",
      "7.92 3.083 5.979 2.985\n",
      "7.99 3.271 5.868 3.444\n",
      "8.33 3.379 5.956 3.612\n",
      "8.7 3.481 6.06 3.782\n",
      "8.92 3.665 5.577 4.289\n",
      "9.26 3.773 5.29 4.506\n",
      "9.64 3.852 4.91 4.632\n"
     ]
    }
   ],
   "source": [
    "# Quick loop to try all split values\n",
    "\n",
    "for split_val in np.unique(xvec)[:-1]:\n",
    "    a_val = np.mean(yvec[xvec<=split_val])\n",
    "    b_val = np.mean(yvec[xvec>split_val])\n",
    "    error_1 = (yvec[xvec<=split_val] - a_val)**2\n",
    "    error_2 = (yvec[xvec>split_val] - b_val)**2\n",
    "    error = np.mean(np.concatenate((error_1, error_2)))\n",
    "    print(split_val, np.round(a_val,decimals=3), \n",
    "          np.round(b_val, decimals=3), np.round(error,decimals=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.collections.LineCollection at 0x12bdd3e80>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Plot best split \n",
    "plt.scatter(xvec, yvec)\n",
    "plt.hlines(y=2.16, xmin=0, xmax=7.15)\n",
    "plt.hlines(y=6.09, xmin=7.15, xmax=10)\n",
    "plt.hlines(y=2.319, xmin=0, xmax=5.45, linestyles='dotted')\n",
    "plt.hlines(y=4.944, xmin=5.45, xmax=10, linestyles='dotted')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Question 1: What about when I want multiple steps?\n",
    "- Let $m$ be number of different x values\n",
    "- To check every division into two steps takes $m$ evaluations\n",
    "- To check every division into three steps takes $m^2$ evaluations\n",
    "- etc....\n",
    "\n",
    "### Question: What about when I have multiple variables?\n",
    "- Again, to find the best step function with say 8 leaves and 4 variables would be very difficult\n",
    "\n",
    "### Solution: Use a greedy approach\n",
    "- Find the best split across all variables\n",
    "- Repeat process on each side of split separately (using only data on that side of split)\n",
    "- Stop according to some rules\n",
    "- Note: This does not find the best possible tree!  For example, it may be that you get the best tree by choosing a \"not-so-good\" split first, but it enables better splits below.\n",
    "\n",
    "### Question: What happens as I keep splitting more and more"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Parameters for decision tree algorithm\n",
    "(I put the sklearn names below, other packages may vary in their naming)\n",
    "- `max_depth`: don't split further when you've reached a certain depth\n",
    "- `min_samples_split`: don't split if you have few data points at the node\n",
    "- `min_samples_leaf`: don't split if it creates a node with few data points\n",
    "- `criterion`: how to evaluate how \"good\" a split is.  Typically use mean_squared_error for regression and entropy for classification (though \"gini\" is also used as a quicker approximation to entropy).  In practice, the distinction between entropy and gini is usually not that important.\n",
    "\n",
    "### Implementation details:\n",
    "- Where should I put the split_value if there are no x values between 1.18 and 3.83 (but that is the best split)?\n",
    "- In other words, for future values between 1.18 and 3.83, should they go \"left\" or \"right\"\n",
    "- What about missing values?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "## Random Forests: Motivating thought experiment\n",
    "- In practice, it is rare to use a single decision tree as your model (though it does happen!)\n",
    "- Imagine you build a decision tree, and at the root it is very close between two different variables as to which is the best to split on.\n",
    "- The \"best\" tree $T_1$ gives a reasonable model. However, you also check what tree you would have built if you used the second-best split (at the root) (call it $T_2$).\n",
    "- Then you average the predictions of $T_1$ and $T_2$ and find it does better than either tree alone\n",
    "- You would like to expand this idea and build 1000 trees that are all \"pretty good\" and also different from one another.\n",
    "- IDEA: inject some randomness into tree building process...\n",
    "\n",
    "### Injecting Randomness\n",
    "The random forest builds many decision trees independently.  Since the decision tree algorithm is deterministic, if you run it over and over again on the same dataset, you will just get the same tree over and over.\n",
    "\n",
    "#### Randomness 1\n",
    "Use different datasets each time.  Specifically, take a random sample of your data (how big? with or without replacement?).  This is called \"bagging\".  This means you can get different trees because the data looks different.\n",
    "- This helps, but the trees end up still being pretty similar most of the time\n",
    "\n",
    "#### Randomness 2\n",
    "Only evaluate a subset of the predictors at each node.  For example, if you have 10 predictors, randomly choose 3 and only consider those.  This means the root splits (and subsequent splits) will be quite different from tree to tree.\n",
    "\n",
    "Since each tree is a completely independent trial of this process, it is straightforward to parallelize."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "jupyter": {
     "outputs_hidden": false
    }
   },
   "source": [
    "### Parameters for Random Forest (in addition to Decision Tree)\n",
    "- all the tree-specific parameters above\n",
    "- `n_estimators`: Number of trees to fit\n",
    "- `max_features`: How many (or what percentage) of the features to try at each node."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's play with some data\n",
    "\n",
    "Our first data set will contain games from the NBA.  We will play around with trying to predict the winner of the game from some team statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor, RandomForestClassifier\n",
    "from sklearn.metrics import log_loss, roc_auc_score, accuracy_score\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23096, 21)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba = pd.read_csv('data/games.csv')\n",
    "df_nba.dropna(inplace=True)\n",
    "df_nba.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>GAME_DATE_EST</th>\n",
       "      <th>GAME_ID</th>\n",
       "      <th>GAME_STATUS_TEXT</th>\n",
       "      <th>HOME_TEAM_ID</th>\n",
       "      <th>VISITOR_TEAM_ID</th>\n",
       "      <th>SEASON</th>\n",
       "      <th>TEAM_ID_home</th>\n",
       "      <th>PTS_home</th>\n",
       "      <th>FG_PCT_home</th>\n",
       "      <th>FT_PCT_home</th>\n",
       "      <th>...</th>\n",
       "      <th>AST_home</th>\n",
       "      <th>REB_home</th>\n",
       "      <th>TEAM_ID_away</th>\n",
       "      <th>PTS_away</th>\n",
       "      <th>FG_PCT_away</th>\n",
       "      <th>FT_PCT_away</th>\n",
       "      <th>FG3_PCT_away</th>\n",
       "      <th>AST_away</th>\n",
       "      <th>REB_away</th>\n",
       "      <th>HOME_TEAM_WINS</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>308</th>\n",
       "      <td>2020-01-13</td>\n",
       "      <td>21900596</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>2019</td>\n",
       "      <td>1610612758</td>\n",
       "      <td>112.0</td>\n",
       "      <td>0.517</td>\n",
       "      <td>0.909</td>\n",
       "      <td>...</td>\n",
       "      <td>25.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>1610612753</td>\n",
       "      <td>114.0</td>\n",
       "      <td>0.435</td>\n",
       "      <td>0.833</td>\n",
       "      <td>0.310</td>\n",
       "      <td>17.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11476</th>\n",
       "      <td>2006-11-08</td>\n",
       "      <td>20600058</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>2006</td>\n",
       "      <td>1610612761</td>\n",
       "      <td>106.0</td>\n",
       "      <td>0.409</td>\n",
       "      <td>0.793</td>\n",
       "      <td>...</td>\n",
       "      <td>19.0</td>\n",
       "      <td>45.0</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.494</td>\n",
       "      <td>0.750</td>\n",
       "      <td>0.250</td>\n",
       "      <td>22.0</td>\n",
       "      <td>53.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14004</th>\n",
       "      <td>2004-12-27</td>\n",
       "      <td>20400399</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>2004</td>\n",
       "      <td>1610612757</td>\n",
       "      <td>104.0</td>\n",
       "      <td>0.482</td>\n",
       "      <td>0.731</td>\n",
       "      <td>...</td>\n",
       "      <td>27.0</td>\n",
       "      <td>48.0</td>\n",
       "      <td>1610612755</td>\n",
       "      <td>111.0</td>\n",
       "      <td>0.446</td>\n",
       "      <td>0.731</td>\n",
       "      <td>0.435</td>\n",
       "      <td>28.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7765</th>\n",
       "      <td>2009-03-10</td>\n",
       "      <td>20800954</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>2008</td>\n",
       "      <td>1610612746</td>\n",
       "      <td>83.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.800</td>\n",
       "      <td>...</td>\n",
       "      <td>20.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1610612739</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.390</td>\n",
       "      <td>0.800</td>\n",
       "      <td>0.150</td>\n",
       "      <td>16.0</td>\n",
       "      <td>46.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13620</th>\n",
       "      <td>2005-02-17</td>\n",
       "      <td>20400781</td>\n",
       "      <td>Final</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>2004</td>\n",
       "      <td>1610612756</td>\n",
       "      <td>113.0</td>\n",
       "      <td>0.453</td>\n",
       "      <td>0.818</td>\n",
       "      <td>...</td>\n",
       "      <td>22.0</td>\n",
       "      <td>41.0</td>\n",
       "      <td>1610612742</td>\n",
       "      <td>119.0</td>\n",
       "      <td>0.536</td>\n",
       "      <td>0.913</td>\n",
       "      <td>0.533</td>\n",
       "      <td>19.0</td>\n",
       "      <td>44.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 21 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      GAME_DATE_EST   GAME_ID GAME_STATUS_TEXT  HOME_TEAM_ID  VISITOR_TEAM_ID  \\\n",
       "308      2020-01-13  21900596            Final    1610612758       1610612753   \n",
       "11476    2006-11-08  20600058            Final    1610612761       1610612755   \n",
       "14004    2004-12-27  20400399            Final    1610612757       1610612755   \n",
       "7765     2009-03-10  20800954            Final    1610612746       1610612739   \n",
       "13620    2005-02-17  20400781            Final    1610612756       1610612742   \n",
       "\n",
       "       SEASON  TEAM_ID_home  PTS_home  FG_PCT_home  FT_PCT_home  ...  \\\n",
       "308      2019    1610612758     112.0        0.517        0.909  ...   \n",
       "11476    2006    1610612761     106.0        0.409        0.793  ...   \n",
       "14004    2004    1610612757     104.0        0.482        0.731  ...   \n",
       "7765     2008    1610612746      83.0        0.390        0.800  ...   \n",
       "13620    2004    1610612756     113.0        0.453        0.818  ...   \n",
       "\n",
       "       AST_home  REB_home  TEAM_ID_away  PTS_away  FG_PCT_away  FT_PCT_away  \\\n",
       "308        25.0      44.0    1610612753     114.0        0.435        0.833   \n",
       "11476      19.0      45.0    1610612755     104.0        0.494        0.750   \n",
       "14004      27.0      48.0    1610612755     111.0        0.446        0.731   \n",
       "7765       20.0      41.0    1610612739      87.0        0.390        0.800   \n",
       "13620      22.0      41.0    1610612742     119.0        0.536        0.913   \n",
       "\n",
       "       FG3_PCT_away  AST_away  REB_away  HOME_TEAM_WINS  \n",
       "308           0.310      17.0      46.0               0  \n",
       "11476         0.250      22.0      53.0               1  \n",
       "14004         0.435      28.0      41.0               0  \n",
       "7765          0.150      16.0      46.0               0  \n",
       "13620         0.533      19.0      44.0               0  \n",
       "\n",
       "[5 rows x 21 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GAME_DATE_EST', 'GAME_ID', 'GAME_STATUS_TEXT', 'HOME_TEAM_ID',\n",
       "       'VISITOR_TEAM_ID', 'SEASON', 'TEAM_ID_home', 'PTS_home', 'FG_PCT_home',\n",
       "       'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', 'TEAM_ID_away',\n",
       "       'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away',\n",
       "       'REB_away', 'HOME_TEAM_WINS'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_nba.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_1 = ['FG_PCT_home','FT_PCT_home', 'FG_PCT_away', 'FT_PCT_away']\n",
    "feat_2 = ['FG_PCT_home','FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', \n",
    "        'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_nba.iloc[:,:-1]  # everything except winner\n",
    "y = df_nba.HOME_TEAM_WINS "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_full, X_test, y_train_full, y_test = train_test_split(X,y,test_size = 2000, random_state=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['GAME_DATE_EST', 'GAME_ID', 'GAME_STATUS_TEXT', 'HOME_TEAM_ID',\n",
       "       'VISITOR_TEAM_ID', 'SEASON', 'TEAM_ID_home', 'PTS_home', 'FG_PCT_home',\n",
       "       'FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', 'TEAM_ID_away',\n",
       "       'PTS_away', 'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away',\n",
       "       'REB_away'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_full.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_train_pts = 2000\n",
    "X_train_1 = X_train_full.iloc[:n_train_pts].loc[:, feat_1]\n",
    "y_train_1 = y_train_full.iloc[:n_train_pts]\n",
    "X_test_1 = X_test.loc[:, feat_1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1 = RandomForestClassifier(n_estimators=1000)\n",
    "rf1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf1.fit(X_train_1, y_train_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_preds_1 = rf1.predict_proba(X_test_1)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.4449462833646558, 0.8687129991972706)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, prob_preds_1), roc_auc_score(y_test, prob_preds_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds_1 = (prob_preds_1 > .5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.794"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, hard_preds_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Now let's repeat with the bigger feature set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_2 = X_train_full.iloc[:n_train_pts].loc[:, feat_2]\n",
    "y_train_2 = y_train_full.iloc[:n_train_pts]\n",
    "X_test_2 = X_test.loc[:, feat_2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "RandomForestClassifier(bootstrap=True, class_weight=None, criterion='gini',\n",
       "                       max_depth=None, max_features='auto', max_leaf_nodes=None,\n",
       "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                       min_samples_leaf=1, min_samples_split=2,\n",
       "                       min_weight_fraction_leaf=0.0, n_estimators=1000,\n",
       "                       n_jobs=None, oob_score=False, random_state=None,\n",
       "                       verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rf2 = RandomForestClassifier(n_estimators=1000)\n",
    "rf2.fit(X_train_2, y_train_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prob_preds_2 = rf2.predict_proba(X_test_2)[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(0.37299959595259247, 0.9146185572613552)"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "log_loss(y_test, prob_preds_2), roc_auc_score(y_test, prob_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "hard_preds_2 = (prob_preds_2>.5).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.838"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "accuracy_score(y_test, hard_preds_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercise:\n",
    "1. Train, Predict and Evaluate Random Forest models using feature sets 3 and 4 below.  Note that 'PTS_home' and 'PTS_away' represent the number of points scored by each team.\n",
    "2. Which model does better?  Why?\n",
    "3. What does this demonstrate about the limitations of the greedy tree-building process?\n",
    "4. What does this demonstrate about the importance of feature engineering?  What feature could be created that would make the RF perform flawlessly?  Why couldn't the RF \"figure it out\" without that feature being made explicit?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_3 = ['FG_PCT_home','FT_PCT_home', 'FG3_PCT_home', 'AST_home', 'REB_home', \n",
    "        'FG_PCT_away', 'FT_PCT_away', 'FG3_PCT_away', 'AST_away', 'REB_away',\n",
    "         'PTS_home', 'PTS_away']\n",
    "feat_4 = ['PTS_home', 'PTS_away']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_3 = X_train_full.iloc[:n_train_pts].loc[:, feat_3]\n",
    "y_train_3 = y_train_full.iloc[:n_train_pts]\n",
    "X_test_3 = X_test.loc[:, feat_3]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_4 = X_train_full.iloc[:n_train_pts].loc[:, feat_4]\n",
    "y_train_4 = y_train_full.iloc[:n_train_pts]\n",
    "X_test_4 = X_test.loc[:, feat_4]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "#..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
